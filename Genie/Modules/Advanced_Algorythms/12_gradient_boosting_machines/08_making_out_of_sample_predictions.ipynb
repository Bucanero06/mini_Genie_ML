{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long-Short Strategy, Part 5: Generating out-of-sample predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll start designing, implementing, and evaluating a trading strategy for US equities driven by daily return forecasts produced by gradient boosting models.\n",
    "\n",
    "As in the previous examples, we'll lay out a framework and build a specific example that you can adapt to run your own experiments. There are numerous aspects that you can vary, from the asset class and investment universe to more granular aspects like the features, holding period, or trading rules. See, for example, the **Alpha Factor Library** in the [Appendix](../24_alpha_factor_library) for numerous additional features.\n",
    "\n",
    "We'll keep the trading strategy simple and only use a single ML signal; a real-life application will likely use multiple signals from different sources, such as complementary ML models trained on different datasets or with different lookahead or lookback periods. It would also use sophisticated risk management, from simple stop-loss to value-at-risk analysis.\n",
    "\n",
    "**Six notebooks** cover our workflow sequence:\n",
    "\n",
    "1. [preparing_the_model_data](04_preparing_the_model_data.ipyny): we engineer a few simple features from the Quandl Wiki data \n",
    "2. [trading_signals_with_lightgbm_and_catboost](05_trading_signals_with_lightgbm_and_catboost.ipynb): we tune hyperparameters for LightGBM and CatBoost to select a model, using 2015/16 as our validation period. \n",
    "3. [evaluate_trading_signals](06_evaluate_trading_signals): we compare the cross-validation performance using various metrics to select the best model. \n",
    "4. [model_interpretation](07_model_interpretation.ipynb): we take a closer look at the drivers behind the best model's predictions.\n",
    "5. `making_out_of_sample_predictions` (this noteboook): we predict returns for our out-of-sample period 2017.\n",
    "6. [backtesting_with_zipline](09_backtesting_with_zipline.ipynb): evaluate the historical performance of a long-short strategy based on our predictive signals using Zipline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:22.754238Z",
     "start_time": "2021-04-16T03:59:22.751670Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T05:08:44.486465Z",
     "start_time": "2021-04-16T05:08:44.469578Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from time import time\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import lightgbm as lgb\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:23.584097Z",
     "start_time": "2021-04-16T03:59:23.581416Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "from utils import MultipleTimeSeriesCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:23.598076Z",
     "start_time": "2021-04-16T03:59:23.585119Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:23.611324Z",
     "start_time": "2021-04-16T03:59:23.598945Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "YEAR = 252\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:23.618708Z",
     "start_time": "2021-04-16T03:59:23.612249Z"
    }
   },
   "outputs": [],
   "source": [
    "scope_params = ['lookahead', 'train_length', 'test_length']\n",
    "daily_ic_metrics = ['daily_ic_mean', 'daily_ic_mean_n', 'daily_ic_median', 'daily_ic_median_n']\n",
    "lgb_train_params = ['learning_rate', 'num_leaves', 'feature_fraction', 'min_data_in_leaf']\n",
    "catboost_train_params = ['max_depth', 'min_child_samples']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate LightGBM predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:23.626636Z",
     "start_time": "2021-04-16T03:59:23.620602Z"
    }
   },
   "outputs": [],
   "source": [
    "base_params = dict(boosting='gbdt',\n",
    "                   objective='regression',\n",
    "                   verbose=-1)\n",
    "\n",
    "categoricals = ['year', 'month', 'sector', 'weekday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:23.637221Z",
     "start_time": "2021-04-16T03:59:23.627969Z"
    }
   },
   "outputs": [],
   "source": [
    "lookahead = 1\n",
    "store = Path('data/predictions.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:24.861291Z",
     "start_time": "2021-04-16T03:59:23.638248Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_hdf('data.h5', 'model_data').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:24.872441Z",
     "start_time": "2021-04-16T03:59:24.862170Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = sorted(data.filter(like='_fwd').columns)\n",
    "features = data.columns.difference(labels).tolist()\n",
    "label = f'r{lookahead:02}_fwd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:25.603772Z",
     "start_time": "2021-04-16T03:59:24.873415Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data.loc[idx[:, '2010':], features + [label]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:25.670973Z",
     "start_time": "2021-04-16T03:59:25.604625Z"
    }
   },
   "outputs": [],
   "source": [
    "for feature in categoricals:\n",
    "    data[feature] = pd.factorize(data[feature], sort=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:25.743036Z",
     "start_time": "2021-04-16T03:59:25.671795Z"
    }
   },
   "outputs": [],
   "source": [
    "lgb_data = lgb.Dataset(data=data[features],\n",
    "                       label=data[label],\n",
    "                       categorical_feature=categoricals,\n",
    "                       free_raw_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:25.860485Z",
     "start_time": "2021-04-16T03:59:25.743923Z"
    }
   },
   "outputs": [],
   "source": [
    "lgb_ic = pd.read_hdf('data/model_tuning.h5', 'lgb/ic')\n",
    "lgb_daily_ic = pd.read_hdf('data/model_tuning.h5', 'lgb/daily_ic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:25.863322Z",
     "start_time": "2021-04-16T03:59:25.861312Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_lgb_params(data, t=5, best=0):\n",
    "    param_cols = scope_params[1:] + lgb_train_params + ['boost_rounds']\n",
    "    df = data[data.lookahead==t].sort_values('ic', ascending=False).iloc[best]\n",
    "    return df.loc[param_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T04:42:08.945191Z",
     "start_time": "2021-04-16T03:59:25.864181Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for position in range(10):\n",
    "    params = get_lgb_params(lgb_daily_ic,\n",
    "                            t=lookahead,\n",
    "                            best=position)\n",
    "\n",
    "    params = params.to_dict()\n",
    "\n",
    "    for p in ['min_data_in_leaf', 'num_leaves']:\n",
    "        params[p] = int(params[p])\n",
    "    train_length = int(params.pop('train_length'))\n",
    "    test_length = int(params.pop('test_length'))\n",
    "    num_boost_round = int(params.pop('boost_rounds'))\n",
    "    params.update(base_params)\n",
    "\n",
    "    print(f'\\nPosition: {position:02}')\n",
    "\n",
    "    # 1-year out-of-sample period\n",
    "    n_splits = int(YEAR / test_length)\n",
    "    cv = MultipleTimeSeriesCV(n_splits=n_splits,\n",
    "                              test_period_length=test_length,\n",
    "                              lookahead=lookahead,\n",
    "                              train_period_length=train_length)\n",
    "\n",
    "    predictions = []\n",
    "    start = time()\n",
    "    for i, (train_idx, test_idx) in enumerate(cv.split(X=data), 1):\n",
    "        print(i, end=' ', flush=True)\n",
    "        lgb_train = lgb_data.subset(used_indices=train_idx.tolist(),\n",
    "                                    params=params).construct()\n",
    "\n",
    "        model = lgb.train(params=params,\n",
    "                          train_set=lgb_train,\n",
    "                          num_boost_round=num_boost_round,\n",
    "                          verbose_eval=False)\n",
    "\n",
    "        test_set = data.iloc[test_idx, :]\n",
    "        y_test = test_set.loc[:, label].to_frame('y_test')\n",
    "        y_pred = model.predict(test_set.loc[:, model.feature_name()])\n",
    "        predictions.append(y_test.assign(prediction=y_pred))\n",
    "\n",
    "    if position == 0:\n",
    "        test_predictions = (pd.concat(predictions)\n",
    "                            .rename(columns={'prediction': position}))\n",
    "    else:\n",
    "        test_predictions[position] = pd.concat(predictions).prediction\n",
    "\n",
    "by_day = test_predictions.groupby(level='date')\n",
    "for position in range(10):\n",
    "    if position == 0:\n",
    "        ic_by_day = by_day.apply(lambda x: spearmanr(\n",
    "            x.y_test, x[position])[0]).to_frame()\n",
    "    else:\n",
    "        ic_by_day[position] = by_day.apply(\n",
    "            lambda x: spearmanr(x.y_test, x[position])[0])\n",
    "print(ic_by_day.describe())\n",
    "test_predictions.to_hdf(store, f'lgb/test/{lookahead:02}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate CatBoost predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T04:47:49.952398Z",
     "start_time": "2021-04-16T04:47:49.946516Z"
    }
   },
   "outputs": [],
   "source": [
    "lookaheads = [1, 5, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T04:47:50.159085Z",
     "start_time": "2021-04-16T04:47:50.155503Z"
    }
   },
   "outputs": [],
   "source": [
    "label_dict = dict(zip(lookaheads, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T04:42:21.239471Z",
     "start_time": "2021-04-16T04:42:21.237509Z"
    }
   },
   "outputs": [],
   "source": [
    "lookahead = 1\n",
    "store = Path('data/predictions.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T04:42:33.046167Z",
     "start_time": "2021-04-16T04:42:30.939809Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_hdf('data.h5', 'model_data').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T04:42:33.057677Z",
     "start_time": "2021-04-16T04:42:33.047222Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = sorted(data.filter(like='_fwd').columns)\n",
    "features = data.columns.difference(labels).tolist()\n",
    "label = f'r{lookahead:02}_fwd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T04:42:34.147080Z",
     "start_time": "2021-04-16T04:42:33.058841Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data.loc[idx[:, '2010':], features + [label]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T04:42:34.278518Z",
     "start_time": "2021-04-16T04:42:34.148155Z"
    }
   },
   "outputs": [],
   "source": [
    "for feature in categoricals:\n",
    "    data[feature] = pd.factorize(data[feature], sort=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T04:49:29.805949Z",
     "start_time": "2021-04-16T04:49:29.799821Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_cols_idx = [data.columns.get_loc(c) for c in categoricals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T04:49:31.122802Z",
     "start_time": "2021-04-16T04:49:30.128972Z"
    }
   },
   "outputs": [],
   "source": [
    "catboost_data = Pool(label=data[label],\n",
    "                     data=data.drop(label, axis=1),\n",
    "                     cat_features=cat_cols_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T05:07:56.282852Z",
     "start_time": "2021-04-16T05:07:56.226707Z"
    }
   },
   "outputs": [],
   "source": [
    "catboost_ic = pd.read_hdf('data/model_tuning.h5', 'catboost/ic')\n",
    "catboost_ic_avg = pd.read_hdf('data/model_tuning.h5', 'catboost/daily_ic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T05:07:57.137679Z",
     "start_time": "2021-04-16T05:07:57.135665Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_cb_params(data, t=5, best=0):\n",
    "    param_cols = scope_params[1:] + catboost_train_params + ['boost_rounds']\n",
    "    df = data[data.lookahead==t].sort_values('ic', ascending=False).iloc[best]\n",
    "    return df.loc[param_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T05:09:16.726292Z",
     "start_time": "2021-04-16T05:08:48.185974Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for position in range(10):\n",
    "    params = get_cb_params(catboost_ic_avg,\n",
    "                    t=lookahead,\n",
    "                    best=position)\n",
    "    \n",
    "    params = params.to_dict()\n",
    "    \n",
    "    for p in ['max_depth', 'min_child_samples']:\n",
    "        params[p] = int(params[p])\n",
    "    train_length = int(params.pop('train_length'))\n",
    "    test_length = int(params.pop('test_length'))\n",
    "    num_boost_round = int(params.pop('boost_rounds'))\n",
    "    params['task_type'] = 'GPU'\n",
    "\n",
    "    print(f'\\nPosition: {position:02}')\n",
    "    \n",
    "    # 1-year out-of-sample period\n",
    "    n_splits = int(YEAR / test_length)\n",
    "    cv = MultipleTimeSeriesCV(n_splits=n_splits,\n",
    "                              test_period_length=test_length,\n",
    "                              lookahead=lookahead,\n",
    "                              train_period_length=train_length)\n",
    "\n",
    "    predictions = []\n",
    "    start = time()\n",
    "    for i, (train_idx, test_idx) in enumerate(cv.split(X=data), 1):\n",
    "        print(i, end=' ', flush=True)\n",
    "        train_set = catboost_data.slice(train_idx.tolist())\n",
    "\n",
    "        model = CatBoostRegressor(**params)\n",
    "        model.fit(X=train_set,\n",
    "                  verbose_eval=False)\n",
    "\n",
    "        test_set = data.iloc[test_idx, :]\n",
    "        y_test = test_set.loc[:, label].to_frame('y_test')\n",
    "        y_pred = model.predict(test_set.loc[:, model.feature_names_])\n",
    "        predictions.append(y_test.assign(prediction=y_pred))\n",
    "\n",
    "    if position == 0:\n",
    "        test_predictions = (pd.concat(predictions)\n",
    "                            .rename(columns={'prediction': position}))\n",
    "    else:\n",
    "        test_predictions[position] = pd.concat(predictions).prediction\n",
    "\n",
    "by_day = test_predictions.groupby(level='date')\n",
    "for position in range(10):\n",
    "    if position == 0:\n",
    "        ic_by_day = by_day.apply(lambda x: spearmanr(x.y_test, x[position])[0]).to_frame()\n",
    "    else:\n",
    "        ic_by_day[position] = by_day.apply(lambda x: spearmanr(x.y_test, x[position])[0])\n",
    "print(ic_by_day.describe())\n",
    "test_predictions.to_hdf(store, f'catboost/test/{lookahead:02}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "301.861px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
