{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "It's highly recommended creating a new virtual environment solely for vectorbtpro, use conda.\n",
    "Documentation access for today [link](vectorbt.pro/pvt_43b09db4)\n",
    "DO NOT SHARE TOKEN FOR VECTORBT, THAT IS FOR MY GITHUB!!! ... I will know ;)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Dont forget to conda install talib {$ means command line :)}\n",
    "$ conda install -c conda-forge ta-lib"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Install vbt\n",
    "# !pip uninstall vectorbt\n",
    "# !pip install -U \"vectorbtpro[base] @ git+https://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@github.com/polakowo/vectorbt.pro.git\"\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Install dask\n",
    "# !pip install dask"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import vectorbtpro as vbt\n",
    "from dask import dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "TrendTimeframe = 'H1'\n",
    "TrendRsi_Window = 13\n",
    "TrendGreen_Window = 2\n",
    "TrendRed_Window = 7\n",
    "TrendBand_Window = 34\n",
    "\n",
    "EntryTimeframe = 'M5'\n",
    "EntryRsi_Window = 13\n",
    "EntryGreen_Window = 2\n",
    "EntryRed_Window = 7\n",
    "EntryBand_Window = 34"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_names = 'XAUUSD.csv'\n",
    "file_dir_paths = \"/home/ruben/PycharmProjects/mini_Genie_ML/New_Nate_Work/Datas/\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fetch_csv_data_dask(data_file_name: object, directory: object = None,\n",
    "                        scheduler='threads', n_rows=None, first_or_last='first',\n",
    "                        ) -> object:\n",
    "    \"\"\"\n",
    "    Loads data from a CSV file into a dask dataframe\n",
    "    :param data_file_name: name of the data file\n",
    "    :param data_file_dir: directory of the data file\n",
    "    :param input_format: format of the date in the data file\n",
    "    :param output_format: format of the date to be outputted\n",
    "    :return: dask dataframe\n",
    "    \"\"\"\n",
    "    first_or_last = first_or_last.lower()\n",
    "\n",
    "    print(f'Loading {data_file_name} from CSV file')\n",
    "    data_file_path = f'{directory}/{data_file_name}'\n",
    "    # add .csv if not present\n",
    "    if not data_file_path.endswith('.csv'):\n",
    "        data_file_path += '.csv'\n",
    "\n",
    "    # load the data into a dask dataframe\n",
    "    # bar_data = dd.read_csv(f'{data_file_dir}/{data_file_name}.csv', parse_dates=True)\n",
    "    if n_rows:\n",
    "        if first_or_last == 'first':\n",
    "            bar_data = dd.read_csv(data_file_path, parse_dates=True, sample=100000000).head(n_rows)\n",
    "        elif first_or_last == 'last':\n",
    "            bar_data = dd.read_csv(data_file_path, parse_dates=True, sample=100000000).tail(n_rows)\n",
    "    else:\n",
    "        bar_data = dd.read_csv(data_file_path, parse_dates=True, sample=100000000)\n",
    "\n",
    "    # convert all column names to upper case\n",
    "    bar_data.columns = bar_data.columns.str.lower()\n",
    "    print(f'Finished Loading {data_file_name} from CSV file')\n",
    "    print(f'Prepping {data_file_name} for use')\n",
    "    # get the name of the datetime column\n",
    "    datetime_col = bar_data.columns[0]\n",
    "    # parse the datetime column\n",
    "\n",
    "    bar_data[datetime_col] = dd.to_datetime(bar_data[datetime_col])\n",
    "    # bar_data[datetime_col] = bar_data[datetime_col].dt.strftime(output_format)\n",
    "    if not n_rows:\n",
    "        # compute the dask dataframe\n",
    "        bar_data = bar_data.compute(scheduler=scheduler)\n",
    "\n",
    "    # set the datetime column as the index\n",
    "    bar_data.index = bar_data[datetime_col]\n",
    "    # delete the datetime column\n",
    "    del bar_data[datetime_col]\n",
    "    return bar_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ohlcv_dataframe = fetch_csv_data_dask(data_file_name=file_names, data_file_dir=file_dir_paths,\n",
    "                                      search_in=(\".\", \"Datas\"), scheduler='threads',\n",
    "                                      n_rows=None, first_or_last='first')\n",
    "ohlcv_dataframe[\"volume\"] = ohlcv_dataframe[\"tick volume\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ohlcv_dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "open = ohlcv_dataframe['open']\n",
    "high = ohlcv_dataframe['high']\n",
    "low = ohlcv_dataframe['low']\n",
    "close = ohlcv_dataframe['close']\n",
    "volume = ohlcv_dataframe['volume']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Trend Computation (use TrendTimeframe):\n",
    "Rsi_Trend = vbt.RSI.run(close, TrendRsi_Window).rsi\n",
    "Green_Trend = vbt.MA.run(Rsi_Trend, TrendGreen_Window)\n",
    "Red_Trend = vbt.MA.run(Rsi_Trend, TrendRed_Window)  # not used"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We calculate a Bollinger Band of the Rsi, only want the \"Middle\" line\n",
    "Bands = vbt.talib('BBANDS').run(Rsi_Trend, TrendBand_Window, 1.6185, 1.6185, 0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Trend Signals (multiple):\n",
    "# Signals are Masks, optimize by selecting either Long_1, Long_2...\n",
    "Long_1_Trend = Bands.middleband_above(50)\n",
    "Long_2_Trend = Green_Trend.ma_above(Bands.middleband)\n",
    "Long_3_Trend = Long_1_Trend | Long_2_Trend\n",
    "Long_4_Trend = Long_1_Trend & Long_2_Trend\n",
    "#\n",
    "Short_1_Trend = Bands.middleband_below(50)\n",
    "Short_2_Trend = Green_Trend.ma_below(Bands.middleband)\n",
    "Short_3_Trend = Short_1_Trend | Short_2_Trend\n",
    "Short_4_Trend = Short_1_Trend & Short_2_Trend"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Entry Computation (use EntryTimeframe):\n",
    "Rsi_Entry = vbt.RSI.run(close, EntryRsi_Window).rsi\n",
    "Green_Entry = vbt.MA.run(Rsi_Entry, EntryGreen_Window)\n",
    "Red_Entry = vbt.MA.run(Rsi_Entry, EntryRed_Window)\n",
    "# We calculate a Bollinger Band of the Rsi, only want the \"Middle\" line\n",
    "Bands = vbt.talib('BBANDS').run(Rsi_Entry, EntryBand_Window, 1.6185, 1.6185, 0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Entry Signals (multiple):\n",
    "# Signals are masks\n",
    "Long_1_Entry = Green_Entry.ma.vbt.crossed_above(Red_Entry.ma)\n",
    "Long_2_Entry = Long_1_Entry & Bands.middleband_above(50)\n",
    "# Long_3_Entry = Long_1_Entry & Green_Entry.ma.combine(Red_Entry.ma).intercept_above(Bands.middleband) # comb needs work\n",
    "#\n",
    "Short_1_Entry = Green_Entry.ma.vbt.crossed_below(Red_Entry.ma)\n",
    "Short_2_Entry = Short_1_Entry & Bands.middleband_below(50)\n",
    "# Short_3_Entry = Short_1_Entry & Green_Entry.ma.combine(Red_Entry.ma).intercept_below(Bands.middleband) # comb needs work"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(Long_1_Entry.head())\n",
    "print(Long_1_Entry.sum())\n",
    "print(Long_2_Entry.head())\n",
    "print(Long_2_Entry.sum())\n",
    "# print(Long_3_Entry.head())\n",
    "print('\\n\\n\\n')\n",
    "print(Short_1_Entry.head())\n",
    "print(Short_1_Entry.sum())\n",
    "print(Short_2_Entry.head())\n",
    "print(Short_2_Entry.sum())\n",
    "# print(Short_3_Entry.head())"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
